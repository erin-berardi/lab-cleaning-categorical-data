{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d365396",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Lab | Cleaning categorical data\n",
    "\n",
    "For this lab, we will be using the dataset in the Customer Analysis Business Case. This dataset can be found in `files_for_lab` folder. In this lab we will explore categorical data.\n",
    "\n",
    "## Data Analysis Process\n",
    "#### Remember the process:\n",
    "\n",
    "- Case Study\n",
    "- **Get data**\n",
    "- **Cleaning/Wrangling/EDA**\n",
    "- Processing Data\n",
    "- Modeling\n",
    " -Validation\n",
    "- Reporting\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Import the necessary libraries load the data and start a new notebook.\n",
    "Using the same data as the previous lab: we_fn_use_c_marketing_customer_value_analysis.csv\n",
    "\n",
    "2. Find  all of the categorical data.  Save it in a categorical_df variable.\n",
    "\n",
    "3. Check for NaN values and decide what to do with them, do it now.\n",
    "\n",
    "4. Check all unique values of columns.\n",
    "\n",
    "5. Check dtypes. Do they all make sense as categorical data?\n",
    "\n",
    "6. Does any column contain alpha and numeric data?  Decide how to clean it and do it now.\n",
    "\n",
    "7. Would you choose to do anything else to clean or wrangle the categorical data?  Comment your decisions and do it now.\n",
    "\n",
    "8. Compare policy_type and policy.  What information is contained in these columns.  Can you identify what is important?  \n",
    "\n",
    "9. Check number of unique values in each column, can they be combined in any way to ease encoding?  Comment your thoughts and make those changes.\n",
    "\n",
    "10.  Save the cleaned catagorical dataframe as categorical.csv   You will use this file again this week.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809a7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "\n",
    "# These are the normal libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# This is just so that we don't get annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# This is the most common viz library in python\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# This one is the above on steroids\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# These Libs are for stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f99598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_Yes</th>\n",
       "      <th>coverage_Extended</th>\n",
       "      <th>coverage_Premium</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>location_code_Suburban</th>\n",
       "      <th>location_code_Urban</th>\n",
       "      <th>marital_status_Married</th>\n",
       "      <th>marital_status_Single</th>\n",
       "      <th>policy_type_Personal Auto</th>\n",
       "      <th>policy_type_Special Auto</th>\n",
       "      <th>vehicle_size_Medsize</th>\n",
       "      <th>vehicle_size_Small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9131</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9132</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9133</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9134 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      response_Yes  coverage_Extended  coverage_Premium  gender_M  \\\n",
       "0                0                  0                 0         0   \n",
       "1                0                  1                 0         0   \n",
       "2                0                  0                 1         0   \n",
       "3                0                  0                 0         1   \n",
       "4                0                  0                 0         1   \n",
       "...            ...                ...               ...       ...   \n",
       "9129             0                  0                 0         1   \n",
       "9130             1                  1                 0         0   \n",
       "9131             0                  1                 0         1   \n",
       "9132             0                  1                 0         1   \n",
       "9133             0                  1                 0         1   \n",
       "\n",
       "      location_code_Suburban  location_code_Urban  marital_status_Married  \\\n",
       "0                          1                    0                       1   \n",
       "1                          1                    0                       0   \n",
       "2                          1                    0                       1   \n",
       "3                          1                    0                       1   \n",
       "4                          0                    0                       0   \n",
       "...                      ...                  ...                     ...   \n",
       "9129                       0                    1                       1   \n",
       "9130                       1                    0                       0   \n",
       "9131                       1                    0                       0   \n",
       "9132                       1                    0                       1   \n",
       "9133                       1                    0                       0   \n",
       "\n",
       "      marital_status_Single  policy_type_Personal Auto  \\\n",
       "0                         0                          0   \n",
       "1                         1                          1   \n",
       "2                         0                          1   \n",
       "3                         0                          0   \n",
       "4                         1                          1   \n",
       "...                     ...                        ...   \n",
       "9129                      0                          1   \n",
       "9130                      0                          0   \n",
       "9131                      1                          0   \n",
       "9132                      0                          1   \n",
       "9133                      1                          0   \n",
       "\n",
       "      policy_type_Special Auto  vehicle_size_Medsize  vehicle_size_Small  \n",
       "0                            0                     1                   0  \n",
       "1                            0                     1                   0  \n",
       "2                            0                     1                   0  \n",
       "3                            0                     1                   0  \n",
       "4                            0                     1                   0  \n",
       "...                        ...                   ...                 ...  \n",
       "9129                         0                     1                   0  \n",
       "9130                         0                     1                   0  \n",
       "9131                         0                     1                   0  \n",
       "9132                         0                     0                   0  \n",
       "9133                         0                     1                   0  \n",
       "\n",
       "[9134 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\filip\\OneDrive\\Desktop\\IRONHACK\\Labs\\Week5\\lab-cleaning-categorical-data\\files_for_lab\\we_fn_use_c_marketing_customer_value_analysis.csv\")\n",
    "\n",
    "cols = []\n",
    "for i in range(len(df.columns)):\n",
    "    cols.append(df.columns[i].lower().replace(' ','_'))\n",
    "df.columns = cols\n",
    "\n",
    "df.dtypes # Checking data types\n",
    "\n",
    "categorical_df = df.select_dtypes(include=['object']) #Saving categorical columns into df\n",
    "\n",
    "categorical_df.isna().sum() #Checking for null values/No null values\n",
    "\n",
    "# Checking unique values in each column\n",
    "categorical_df['customer'].unique() #Categorical\n",
    "categorical_df['state'].unique() #Categorical\n",
    "categorical_df['response'].unique() #Categorical\n",
    "categorical_df['coverage'].unique() #Categorical\n",
    "categorical_df['education'].unique() #Categorical\n",
    "categorical_df['effective_to_date'].unique() #Date Time\n",
    "categorical_df['employmentstatus'].unique() #Categorical\n",
    "categorical_df['gender'].unique() #Categorical\n",
    "categorical_df['location_code'].unique() #Categorical\n",
    "categorical_df['marital_status'].unique() #Categorical\n",
    "categorical_df['policy_type'].unique() #Categorical\n",
    "categorical_df['policy'].unique() #Categorical\n",
    "categorical_df['renew_offer_type'].unique() #Categorical\n",
    "categorical_df['sales_channel'].unique() #Categorical\n",
    "categorical_df['vehicle_class'].unique() #Categorical\n",
    "categorical_df['vehicle_size'].unique() #Categorical\n",
    "\n",
    "# will drop effective_to_date and later if needed will convert to datetime on the original df\n",
    "\n",
    "categorical_df = categorical_df.drop(['effective_to_date'], axis = 1)\n",
    "\n",
    "# will also drop customer because it doesn't really give us any information\n",
    "\n",
    "categorical_df = categorical_df.drop(['customer'], axis = 1)\n",
    "\n",
    "categorical_df['policy_type'].unique() #Categorical\n",
    "\n",
    "'''policy_type has the following unique values:['Corporate Auto', 'Personal Auto', 'Special Auto']\n",
    "\n",
    "   policy has the following unique values:['Corporate L3', 'Personal L3', 'Corporate L2', 'Personal L1',\n",
    "    'Special L2', 'Corporate L1', 'Personal L2', 'Special L1','Special L3']\n",
    "    \n",
    "It appears that the values in policy are the same as in policy_type but broken down into subtypes, more detailed information.\n",
    "\n",
    "I would drop policy if in need to drop one of the two''' \n",
    "\n",
    "# Variables I would chose to hot encode\n",
    "categorical_df['response'].unique()\n",
    "categorical_df['coverage'].unique()\n",
    "categorical_df['gender'].unique()\n",
    "categorical_df['location_code'].unique()\n",
    "categorical_df['marital_status'].unique()\n",
    "categorical_df['policy_type'].unique()\n",
    "categorical_df['vehicle_size'].unique()\n",
    "\n",
    "# In my opinion these columns have too many values to hot encode, will drop for now\n",
    "categorical_df['state'].unique()\n",
    "categorical_df['education'].unique()\n",
    "categorical_df['employmentstatus'].unique()\n",
    "categorical_df['policy'].unique()\n",
    "categorical_df['renew_offer_type'].unique()\n",
    "categorical_df['sales_channel'].unique()\n",
    "categorical_df['vehicle_class'].unique()\n",
    "\n",
    "categorical_df = categorical_df.drop(['state','education','employmentstatus','policy','renew_offer_type','sales_channel','vehicle_class'], axis = 1)\n",
    "\n",
    "# One hot encoding chosen columns\n",
    "\n",
    "categorical_df = pd.get_dummies(categorical_df, drop_first=True)\n",
    "categorical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f1192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data frame\n",
    "\n",
    "categorical_df.to_csv('Categorical DF.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5a5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
